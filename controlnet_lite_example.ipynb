{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U torch diffusers>=0.22.0 transformers accelerate ftfy triton safetensors\n",
    "import diffusers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download weights\n",
    "!wget https://huggingface.co/lllyasviel/sd_control_collection/resolve/main/kohya_controllllite_xl_canny.safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "\n",
    "pipeline = diffusers.StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\", \n",
    "    torch_dtype=torch.float16, \n",
    "    variant=\"fp16\"\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from controlnet_lite import ControlNetLLLite\n",
    "\n",
    "# Load ControlNetLllite weights \n",
    "path = 'kohya_controllllite_xl_canny.safetensors'\n",
    "controlnet = ControlNetLLLite(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load Control Image\n",
    "image = diffusers.utils.load_image(\"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_controlnet/hf-logo.png\")\n",
    "# Convert the image to numpy array\n",
    "control_image = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioning_weight = 1\n",
    "# Currently there is no way to control start and end of the conditioning\n",
    "# As it can only be controled from the diffusers.DiffusionPipeline, and will require\n",
    "# separate custom pipeline for Txt2Img, Img2Img etc.\n",
    "# TODO: figure out smart way to bypass this\n",
    "\n",
    "# Apply ControlNetLLLite to the pipeline\n",
    "controlnet.apply(pipe=pipeline, cond=control_image, weight=conditioning_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "        image = pipeline(prompt=\"aerial view, a futuristic research complex in a bright foggy jungle, hard lighting\", num_inference_steps=20).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To unload all controlnetLite modules from the pipeline\n",
    "from controlnet_lite import clear_all_lllite\n",
    "clear_all_lllite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "        image = pipeline(prompt=\"aerial view, a futuristic research complex in a bright foggy jungle, hard lighting\", num_inference_steps=20).images[0]\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
